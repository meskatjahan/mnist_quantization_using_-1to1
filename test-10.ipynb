{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180284d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q keras\n",
    "\n",
    "\n",
    "## Imports libs\n",
    "import os\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e5540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import SVHN\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d2cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    " !pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc341b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4fa8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d85fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1cc94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "484fbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(120, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67875e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3602657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08515477, 0.46890438, 0.        , 0.6840158 , 0.43914342,\n",
       "        0.        , 0.20039785, 0.04518325, 0.        , 0.38210383,\n",
       "        0.32413572, 0.        , 0.        , 0.09487971, 0.        ,\n",
       "        0.41452473, 0.11631904, 0.6179367 , 0.        , 0.        ,\n",
       "        0.07515227, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15303041, 0.05941117, 0.        , 0.04772422, 0.7050082 ,\n",
       "        0.        , 0.        , 0.06589548, 0.        , 0.44849604,\n",
       "        0.2860181 , 0.        , 0.5380732 , 0.07917921, 0.        ,\n",
       "        0.02565396, 0.0658457 , 0.        , 0.        , 0.4498542 ,\n",
       "        0.        , 0.        , 0.        , 0.4117778 , 0.4332118 ,\n",
       "        0.        , 0.        , 0.        , 0.44391543, 0.23069452,\n",
       "        0.        , 0.6298229 , 0.        , 0.31671488, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.15147167, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.46506783, 0.        ,\n",
       "        0.9652528 , 0.        , 0.        , 0.53224045, 0.19876298,\n",
       "        0.        , 0.        , 0.        , 0.19888397, 0.        ,\n",
       "        0.49257445, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.518219  , 0.40077028, 0.11556316, 0.83404326,\n",
       "        0.6086582 , 0.        , 0.2865252 , 0.58378386, 0.00951848,\n",
       "        0.28576967, 0.23603463, 0.        , 0.2884804 , 0.        ,\n",
       "        0.        , 0.        , 0.615057  , 0.        , 0.53351384,\n",
       "        0.        , 1.0223708 , 0.        , 0.        , 0.20043774,\n",
       "        0.16547737, 0.        , 0.        , 0.29461807, 0.        ,\n",
       "        0.        , 0.        , 0.5372112 , 0.        , 0.19678107]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e46bdb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00743183, 0.01090827, 0.00682517, 0.01352626, 0.01058841,\n",
       "        0.00682517, 0.0083396 , 0.00714062, 0.00682517, 0.01000136,\n",
       "        0.00943808, 0.00682517, 0.00682517, 0.00750445, 0.00682517,\n",
       "        0.01033092, 0.00766708, 0.01266134, 0.00682517, 0.00682517,\n",
       "        0.00735786, 0.00682517, 0.00682517, 0.00682517, 0.00682517,\n",
       "        0.00795378, 0.00724295, 0.00682517, 0.00715879, 0.01381321,\n",
       "        0.00682517, 0.00682517, 0.00729006, 0.00682517, 0.01068791,\n",
       "        0.00908509, 0.00682517, 0.01168949, 0.00738755, 0.00682517,\n",
       "        0.00700253, 0.0072897 , 0.00682517, 0.00682517, 0.01070243,\n",
       "        0.00682517, 0.00682517, 0.00682517, 0.01030258, 0.01052579,\n",
       "        0.00682517, 0.00682517, 0.00682517, 0.01063906, 0.00859612,\n",
       "        0.00682517, 0.01281274, 0.00682517, 0.0093683 , 0.00682517,\n",
       "        0.00682517, 0.00682517, 0.00682517, 0.00794139, 0.00682517,\n",
       "        0.00682517, 0.00682517, 0.00682517, 0.0108665 , 0.00682517,\n",
       "        0.01791915, 0.00682517, 0.00682517, 0.01162151, 0.00832597,\n",
       "        0.00682517, 0.00682517, 0.00682517, 0.00832698, 0.00682517,\n",
       "        0.01116955, 0.00682517, 0.00682517, 0.00682517, 0.00682517,\n",
       "        0.00682517, 0.01145969, 0.0101898 , 0.00766129, 0.0157157 ,\n",
       "        0.01254441, 0.00682517, 0.0090897 , 0.01223622, 0.00689044,\n",
       "        0.00908284, 0.00864215, 0.00682517, 0.00910749, 0.00682517,\n",
       "        0.00682517, 0.00682517, 0.01262494, 0.00682517, 0.01163631,\n",
       "        0.00682517, 0.01897245, 0.00682517, 0.00682517, 0.00833993,\n",
       "        0.0080534 , 0.00682517, 0.00682517, 0.00916356, 0.00682517,\n",
       "        0.00682517, 0.00682517, 0.01167942, 0.00682517, 0.00830949]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf7a0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f2991d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9871387"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7334d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390861f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67138d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.7036 - accuracy: 0.6723\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6829 - accuracy: 0.6769\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6825 - accuracy: 0.6774\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6752 - accuracy: 0.6786\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6718 - accuracy: 0.6794\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6797 - accuracy: 0.6784\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6633 - accuracy: 0.6818\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6751 - accuracy: 0.6790\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6600 - accuracy: 0.6830\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6726 - accuracy: 0.6813\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.6612 - accuracy: 0.6821\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6637 - accuracy: 0.6822\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6601 - accuracy: 0.6830\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6607 - accuracy: 0.6837\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6645 - accuracy: 0.6820\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6634 - accuracy: 0.6824\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6636 - accuracy: 0.6828\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6451 - accuracy: 0.6854\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6510 - accuracy: 0.6845\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6633 - accuracy: 0.6829\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6542 - accuracy: 0.6853\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6547 - accuracy: 0.6840\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6466 - accuracy: 0.6855\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6485 - accuracy: 0.6849\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6502 - accuracy: 0.6853\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6635 - accuracy: 0.6831\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 2s 994us/step - loss: 1.6644 - accuracy: 0.6826\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 2s 999us/step - loss: 1.6509 - accuracy: 0.6850\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 2s 992us/step - loss: 1.6602 - accuracy: 0.6823\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6388 - accuracy: 0.6875\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6686 - accuracy: 0.6815\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6481 - accuracy: 0.6855\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.6509 - accuracy: 0.6849\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6486 - accuracy: 0.6862\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6466 - accuracy: 0.6858\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6480 - accuracy: 0.6864\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6542 - accuracy: 0.6844\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6480 - accuracy: 0.6849\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6392 - accuracy: 0.6878\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6512 - accuracy: 0.6854\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6527 - accuracy: 0.6858\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6545 - accuracy: 0.6848\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6455 - accuracy: 0.6854\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6330 - accuracy: 0.6881\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6446 - accuracy: 0.6872\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6453 - accuracy: 0.6860\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6377 - accuracy: 0.6874\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6645 - accuracy: 0.6840\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6478 - accuracy: 0.6868\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6423 - accuracy: 0.6882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2950cfdc8b0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada95481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9848703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLay  (None, 28, 28)           3         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " quant_flatten_11 (QuantizeW  (None, 784)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_12 (QuantizeWra  (None, 120)              94205     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dropout_11 (QuantizeW  (None, 120)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,210\n",
      "Trainable params: 94,200\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model=model\n",
    "\n",
    "quant_aware_model = tfmot.quantization.keras.quantize_model(base_model)\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fff08bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LastValueQuantizer = tfmot.quantization.keras.quantizers.LastValueQuantizer\n",
    "MovingAverageQuantizer = tfmot.quantization.keras.quantizers.MovingAverageQuantizer\n",
    "\n",
    "class DefaultDenseQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    # Configure how to quantize weights.\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "      return [(layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    # Configure how to quantize activations.\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "      return [(layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
    "      # , in the same order\n",
    "      layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
    "      # , in the same order.\n",
    "      layer.activation = quantize_activations[0]\n",
    "\n",
    "    # Configure how to quantize outputs (may be equivalent to activations).\n",
    "    def get_output_quantizers(self, layer):\n",
    "      return []\n",
    "\n",
    "    def get_config(self):\n",
    "      return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dcaad375",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "quantize_annotate_model = tfmot.quantization.keras.quantize_annotate_model\n",
    "quantize_scope = tfmot.quantization.keras.quantize_scope\n",
    "\n",
    "class FixedRangeQuantizer(tfmot.quantization.keras.quantizers.Quantizer):\n",
    "  \"\"\"Quantizer which forces outputs to be between -1 and 1.\"\"\"\n",
    "\n",
    "  def build(self, tensor_shape, name, layer):\n",
    "    # Not needed. No new TensorFlow variables needed.\n",
    "    return {}\n",
    "\n",
    "  def __call__(self, inputs, training, weights, **kwargs):\n",
    "    return tf.keras.backend.clip(inputs, -1.0, 1.0)\n",
    "\n",
    "  def get_config(self):\n",
    "    # Not needed. No __init__ parameters to serialize.\n",
    "    return {}\n",
    "\n",
    "\n",
    "class ModifiedDenseQuantizeConfig(DefaultDenseQuantizeConfig):\n",
    "    # Configure weights to quantize with 4-bit instead of 8-bits.\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "      # Use custom algorithm defined in `FixedRangeQuantizer` instead of default Quantizer.\n",
    "      return [(layer.kernel, FixedRangeQuantizer())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "586e734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_1 (QuantizeL  (None, 28, 28)           3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_flatten_12 (QuantizeW  (None, 784)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_13 (QuantizeWra  (None, 129)              101268    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,272\n",
      "Trainable params: 101,265\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = quantize_annotate_model(tf.keras.Sequential([\n",
    "   \n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Pass in modified `QuantizeConfig` to modify this `Dense` layer.\n",
    "   quantize_annotate_layer(tf.keras.layers.Dense(129,), ModifiedDenseQuantizeConfig()),\n",
    "    \n",
    "]))\n",
    "\n",
    "# `quantize_apply` requires mentioning `ModifiedDenseQuantizeConfig` with `quantize_scope`:\n",
    "with quantize_scope(\n",
    "  {'ModifiedDenseQuantizeConfig': ModifiedDenseQuantizeConfig}):\n",
    "  # Use `quantize_apply` to actually make the model quantization aware.\n",
    "  quant_aware_model = tfmot.quantization.keras.quantize_apply(model)\n",
    "\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "21159718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.8912 - accuracy: 0.8378 - 340ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8912105560302734, 0.8378000259399414]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a7d54f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_1 (QuantizeL  (None, 28, 28)           3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_flatten_12 (QuantizeW  (None, 784)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_13 (QuantizeWra  (None, 129)              101268    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,272\n",
      "Trainable params: 101,265\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# `quantize_model` requires a recompile.\n",
    "quant_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f78cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2624 - accuracy: 0.9267\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2584 - accuracy: 0.9279\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2561 - accuracy: 0.9294\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2545 - accuracy: 0.9299\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2525 - accuracy: 0.9301\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2508 - accuracy: 0.9310\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2496 - accuracy: 0.9313\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2486 - accuracy: 0.9304\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2471 - accuracy: 0.9319\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2463 - accuracy: 0.9316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29513bb1cd0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_aware_model.fit(x_train, y_train,   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa23c9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27312198281288147, 0.9261000156402588]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_aware_model.evaluate(x_test,  y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c8abfb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "14b1921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7875999808311462\n",
      "Quantize test accuracy: 0.8991000056266785\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = base_model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "_, quant_aware_model_accuracy = quant_aware_model.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quantize test accuracy:', quant_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44537dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as flatten_12_layer_call_fn, flatten_12_layer_call_and_return_conditional_losses, dense_13_layer_call_fn, dense_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Windows\\TEMP\\tmp32tyoj3q\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Windows\\TEMP\\tmp32tyoj3q\\assets\n",
      "C:\\Users\\Meskat Jahan\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model11 = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fde3a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f8eec64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.8986\n",
      "Quant TF test accuracy: 0.8991000056266785\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model11)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', quant_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6326273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.8986\n",
      "Quant TF test accuracy: 0.8991000056266785\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model11)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', quant_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8012279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Windows\\TEMP\\tmp6t0nm_f1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Windows\\TEMP\\tmp6t0nm_f1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model in Mb: 0.3607063293457031\n",
      "Quantized model in Mb: 0.0988922119140625\n"
     ]
    }
   ],
   "source": [
    "# Create float TFLite model.\n",
    "float_converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "float_tflite_model12 = float_converter.convert()\n",
    "\n",
    "\n",
    "# Measure sizes of models.\n",
    "_, float_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quant_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model11)\n",
    "\n",
    "with open(float_file, 'wb') as f:\n",
    "  f.write(float_tflite_model12)\n",
    "\n",
    "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
    "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735a007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
